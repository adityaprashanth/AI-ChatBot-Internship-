{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11bbe1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying all the things present in the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e09c526a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Data for actor:\n",
      "     actor_id first_name     last_name             last_update\n",
      "0           1   Penelope       Guiness 2013-05-26 14:47:57.620\n",
      "1           2       Nick      Wahlberg 2013-05-26 14:47:57.620\n",
      "2           3         Ed         Chase 2013-05-26 14:47:57.620\n",
      "3           4   Jennifer         Davis 2013-05-26 14:47:57.620\n",
      "4           5     Johnny  Lollobrigida 2013-05-26 14:47:57.620\n",
      "..        ...        ...           ...                     ...\n",
      "195       196       Bela        Walken 2013-05-26 14:47:57.620\n",
      "196       197      Reese          West 2013-05-26 14:47:57.620\n",
      "197       198       Mary        Keitel 2013-05-26 14:47:57.620\n",
      "198       199      Julia       Fawcett 2013-05-26 14:47:57.620\n",
      "199       200      Thora        Temple 2013-05-26 14:47:57.620\n",
      "\n",
      "[200 rows x 4 columns]\n",
      "\n",
      "Retrieved Data for film:\n",
      "     film_id              title  \\\n",
      "0        133    Chamber Italian   \n",
      "1        384   Grosse Wonderful   \n",
      "2          8    Airport Pollock   \n",
      "3         98  Bright Encounters   \n",
      "4          1   Academy Dinosaur   \n",
      "..       ...                ...   \n",
      "995      996     Young Language   \n",
      "996      997         Youth Kick   \n",
      "997      998       Zhivago Core   \n",
      "998      999  Zoolander Fiction   \n",
      "999     1000          Zorro Ark   \n",
      "\n",
      "                                           description  release_year  \\\n",
      "0    A Fateful Reflection of a Moose And a Husband ...          2006   \n",
      "1    A Epic Drama of a Cat And a Explorer who must ...          2006   \n",
      "2    A Epic Tale of a Moose And a Girl who must Con...          2006   \n",
      "3    A Fateful Yarn of a Lumberjack And a Feminist ...          2006   \n",
      "4    A Epic Drama of a Feminist And a Mad Scientist...          2006   \n",
      "..                                                 ...           ...   \n",
      "995  A Unbelieveable Yarn of a Boat And a Database ...          2006   \n",
      "996  A Touching Drama of a Teacher And a Cat who mu...          2006   \n",
      "997  A Fateful Yarn of a Composer And a Man who mus...          2006   \n",
      "998  A Fateful Reflection of a Waitress And a Boat ...          2006   \n",
      "999  A Intrepid Panorama of a Mad Scientist And a B...          2006   \n",
      "\n",
      "     language_id  rental_duration rental_rate  length replacement_cost rating  \\\n",
      "0              1                7        4.99     117            14.99  NC-17   \n",
      "1              1                5        4.99      49            19.99      R   \n",
      "2              1                6        4.99      54            15.99      R   \n",
      "3              1                4        4.99      73            12.99  PG-13   \n",
      "4              1                6        0.99      86            20.99     PG   \n",
      "..           ...              ...         ...     ...              ...    ...   \n",
      "995            1                6        0.99     183             9.99      G   \n",
      "996            1                4        0.99     179            14.99  NC-17   \n",
      "997            1                6        0.99     105            10.99  NC-17   \n",
      "998            1                5        2.99     101            28.99      R   \n",
      "999            1                3        4.99      50            18.99  NC-17   \n",
      "\n",
      "                last_update                             special_features  \\\n",
      "0   2013-05-26 14:50:58.951                                   [Trailers]   \n",
      "1   2013-05-26 14:50:58.951                          [Behind the Scenes]   \n",
      "2   2013-05-26 14:50:58.951                                   [Trailers]   \n",
      "3   2013-05-26 14:50:58.951                                   [Trailers]   \n",
      "4   2013-05-26 14:50:58.951          [Deleted Scenes, Behind the Scenes]   \n",
      "..                      ...                                          ...   \n",
      "995 2013-05-26 14:50:58.951                [Trailers, Behind the Scenes]   \n",
      "996 2013-05-26 14:50:58.951                [Trailers, Behind the Scenes]   \n",
      "997 2013-05-26 14:50:58.951                             [Deleted Scenes]   \n",
      "998 2013-05-26 14:50:58.951                   [Trailers, Deleted Scenes]   \n",
      "999 2013-05-26 14:50:58.951  [Trailers, Commentaries, Behind the Scenes]   \n",
      "\n",
      "                                              fulltext  \n",
      "0    'chamber':1 'fate':4 'husband':11 'italian':2 ...  \n",
      "1    'australia':18 'cat':8 'drama':5 'epic':4 'exp...  \n",
      "2    'airport':1 'ancient':18 'confront':14 'epic':...  \n",
      "3    'boat':20 'bright':1 'conquer':14 'encount':2 ...  \n",
      "4    'academi':1 'battl':15 'canadian':20 'dinosaur...  \n",
      "..                                                 ...  \n",
      "995  'administr':12 'boat':8 'boy':17 'databas':11 ...  \n",
      "996  'boat':22 'cat':11 'challeng':14 'drama':5 'ki...  \n",
      "997  'boy':16 'canadian':19 'compos':8 'core':2 'fa...  \n",
      "998  'ancient':19 'boat':11 'china':20 'discov':14 ...  \n",
      "999  'ark':2 'boy':12,17 'intrepid':4 'mad':8 'mona...  \n",
      "\n",
      "[1000 rows x 13 columns]\n",
      "\n",
      "Retrieved Data for film_actor:\n",
      "      actor_id  film_id         last_update\n",
      "0            1        1 2006-02-15 10:05:03\n",
      "1            1       23 2006-02-15 10:05:03\n",
      "2            1       25 2006-02-15 10:05:03\n",
      "3            1      106 2006-02-15 10:05:03\n",
      "4            1      140 2006-02-15 10:05:03\n",
      "...        ...      ...                 ...\n",
      "5457       200      879 2006-02-15 10:05:03\n",
      "5458       200      912 2006-02-15 10:05:03\n",
      "5459       200      945 2006-02-15 10:05:03\n",
      "5460       200      958 2006-02-15 10:05:03\n",
      "5461       200      993 2006-02-15 10:05:03\n",
      "\n",
      "[5462 rows x 3 columns]\n",
      "\n",
      "Retrieved Data for customer:\n",
      "     customer_id  store_id first_name  last_name  \\\n",
      "0            524         1      Jared        Ely   \n",
      "1              1         1       Mary      Smith   \n",
      "2              2         1   Patricia    Johnson   \n",
      "3              3         1      Linda   Williams   \n",
      "4              4         2    Barbara      Jones   \n",
      "..           ...       ...        ...        ...   \n",
      "594          595         1   Terrence  Gunderson   \n",
      "595          596         1    Enrique   Forsythe   \n",
      "596          597         1    Freddie     Duggan   \n",
      "597          598         1       Wade   Delvalle   \n",
      "598          599         2     Austin    Cintron   \n",
      "\n",
      "                                     email  address_id  activebool  \\\n",
      "0             jared.ely@sakilacustomer.org         530        True   \n",
      "1            mary.smith@sakilacustomer.org           5        True   \n",
      "2      patricia.johnson@sakilacustomer.org           6        True   \n",
      "3        linda.williams@sakilacustomer.org           7        True   \n",
      "4         barbara.jones@sakilacustomer.org           8        True   \n",
      "..                                     ...         ...         ...   \n",
      "594  terrence.gunderson@sakilacustomer.org         601        True   \n",
      "595    enrique.forsythe@sakilacustomer.org         602        True   \n",
      "596      freddie.duggan@sakilacustomer.org         603        True   \n",
      "597       wade.delvalle@sakilacustomer.org         604        True   \n",
      "598      austin.cintron@sakilacustomer.org         605        True   \n",
      "\n",
      "    create_date             last_update  active  \n",
      "0    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "1    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "2    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "3    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "4    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "..          ...                     ...     ...  \n",
      "594  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "595  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "596  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "597  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "598  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "\n",
      "[599 rows x 10 columns]\n",
      "\n",
      "Retrieved Data for payment:\n",
      "       payment_id  customer_id  staff_id  rental_id amount  \\\n",
      "0           17503          341         2       1520   7.99   \n",
      "1           17504          341         1       1778   1.99   \n",
      "2           17505          341         1       1849   7.99   \n",
      "3           17506          341         2       2829   2.99   \n",
      "4           17507          341         2       3130   7.99   \n",
      "...           ...          ...       ...        ...    ...   \n",
      "14591       32094          245         2      12682   2.99   \n",
      "14592       32095          251         1      14107   0.99   \n",
      "14593       32096          252         2      13756   4.99   \n",
      "14594       32097          263         1      15293   0.99   \n",
      "14595       32098          264         2      14243   2.99   \n",
      "\n",
      "                    payment_date  \n",
      "0     2007-02-15 22:25:46.996577  \n",
      "1     2007-02-16 17:23:14.996577  \n",
      "2     2007-02-16 22:41:45.996577  \n",
      "3     2007-02-19 19:39:56.996577  \n",
      "4     2007-02-20 17:31:48.996577  \n",
      "...                          ...  \n",
      "14591 2007-05-14 13:44:29.996577  \n",
      "14592 2007-05-14 13:44:29.996577  \n",
      "14593 2007-05-14 13:44:29.996577  \n",
      "14594 2007-05-14 13:44:29.996577  \n",
      "14595 2007-05-14 13:44:29.996577  \n",
      "\n",
      "[14596 rows x 6 columns]\n",
      "\n",
      "Retrieved Data for address:\n",
      "     address_id                   address address2      district  city_id  \\\n",
      "0             1         47 MySakila Drive     None       Alberta      300   \n",
      "1             2        28 MySQL Boulevard     None           QLD      576   \n",
      "2             3         23 Workhaven Lane     None       Alberta      300   \n",
      "3             4      1411 Lillydale Drive     None           QLD      576   \n",
      "4             5            1913 Hanoi Way               Nagasaki      463   \n",
      "..          ...                       ...      ...           ...      ...   \n",
      "598         601       844 Bucuresti Place               Liaoning      242   \n",
      "599         602  1101 Bucuresti Boulevard            West Greece      401   \n",
      "600         603    1103 Quilmes Boulevard                  Piura      503   \n",
      "601         604       1331 Usak Boulevard                   Vaud      296   \n",
      "602         605      1325 Fukuyama Street           Heilongjiang      537   \n",
      "\n",
      "    postal_code         phone         last_update  \n",
      "0                             2006-02-15 09:45:30  \n",
      "1                             2006-02-15 09:45:30  \n",
      "2                 14033335568 2006-02-15 09:45:30  \n",
      "3                  6172235589 2006-02-15 09:45:30  \n",
      "4         35200   28303384290 2006-02-15 09:45:30  \n",
      "..          ...           ...                 ...  \n",
      "598       36603  935952366111 2006-02-15 09:45:30  \n",
      "599       97661  199514580428 2006-02-15 09:45:30  \n",
      "600       52137  644021380889 2006-02-15 09:45:30  \n",
      "601       61960  145308717464 2006-02-15 09:45:30  \n",
      "602       27107  288241215394 2006-02-15 09:45:30  \n",
      "\n",
      "[603 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Data for rental:\n",
      "       rental_id         rental_date  inventory_id  customer_id  \\\n",
      "0              2 2005-05-24 22:54:33          1525          459   \n",
      "1              3 2005-05-24 23:03:39          1711          408   \n",
      "2              4 2005-05-24 23:04:41          2452          333   \n",
      "3              5 2005-05-24 23:05:21          2079          222   \n",
      "4              6 2005-05-24 23:08:07          2792          549   \n",
      "...          ...                 ...           ...          ...   \n",
      "16039      16046 2005-08-23 22:26:47          4364           74   \n",
      "16040      16047 2005-08-23 22:42:48          2088          114   \n",
      "16041      16048 2005-08-23 22:43:07          2019          103   \n",
      "16042      16049 2005-08-23 22:50:12          2666          393   \n",
      "16043          1 2005-05-24 22:53:30           367          130   \n",
      "\n",
      "              return_date  staff_id         last_update  \n",
      "0     2005-05-28 19:40:33         1 2006-02-16 02:30:53  \n",
      "1     2005-06-01 22:12:39         1 2006-02-16 02:30:53  \n",
      "2     2005-06-03 01:43:41         2 2006-02-16 02:30:53  \n",
      "3     2005-06-02 04:33:21         1 2006-02-16 02:30:53  \n",
      "4     2005-05-27 01:32:07         1 2006-02-16 02:30:53  \n",
      "...                   ...       ...                 ...  \n",
      "16039 2005-08-27 18:02:47         2 2006-02-16 02:30:53  \n",
      "16040 2005-08-25 02:48:48         2 2006-02-16 02:30:53  \n",
      "16041 2005-08-31 21:33:07         1 2006-02-16 02:30:53  \n",
      "16042 2005-08-30 01:01:12         2 2006-02-16 02:30:53  \n",
      "16043 2005-05-26 22:04:30         1 2006-02-15 21:30:53  \n",
      "\n",
      "[16044 rows x 7 columns]\n",
      "\n",
      "Retrieved Data for inventory:\n",
      "      inventory_id  film_id  store_id         last_update\n",
      "0                1        1         1 2006-02-15 10:09:17\n",
      "1                2        1         1 2006-02-15 10:09:17\n",
      "2                3        1         1 2006-02-15 10:09:17\n",
      "3                4        1         1 2006-02-15 10:09:17\n",
      "4                5        1         2 2006-02-15 10:09:17\n",
      "...            ...      ...       ...                 ...\n",
      "4576          4577     1000         1 2006-02-15 10:09:17\n",
      "4577          4578     1000         2 2006-02-15 10:09:17\n",
      "4578          4579     1000         2 2006-02-15 10:09:17\n",
      "4579          4580     1000         2 2006-02-15 10:09:17\n",
      "4580          4581     1000         2 2006-02-15 10:09:17\n",
      "\n",
      "[4581 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "# Function to query data from PostgreSQL\n",
    "def query_data(table_name):\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT * FROM {table_name}\"))\n",
    "        data = result.fetchall()\n",
    "        return pd.DataFrame(data, columns=result.keys())\n",
    "\n",
    "# List of tables to query\n",
    "tables = ['actor', 'film', 'film_actor', 'customer', 'payment', 'address', 'rental', 'inventory']\n",
    "\n",
    "# Retrieve data from PostgreSQL and display all columns for each table\n",
    "for table in tables:\n",
    "    data = query_data(table)\n",
    "    print(f\"\\nRetrieved Data for {table}:\")\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d973eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9483a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to connect to vertex AI (Not possible since don't have endpoint as I didn't train a model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977cfe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1129dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-cloud-aiplatform in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (1.53.0)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (2.0.30)\n",
      "Requirement already satisfied: psycopg2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (2.9.9)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (23.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (1.23.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.29.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.19.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.16.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (4.25.3)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (1.12.3)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (3.24.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-aiplatform) (2.7.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from sqlalchemy) (4.12.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy) (1.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.1)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.27.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.64.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.2.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.18.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-aiplatform sqlalchemy psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ad08053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable for Google Cloud authentication\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/adity/Downloads/ordinal-city-425315-r1-e1ea6aff2773.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c5c9b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Adam', 'Grant')\n",
      "('Adam', 'Hopper')\n",
      "('Al', 'Garland')\n",
      "('Alan', 'Dreyfuss')\n",
      "('Albert', 'Johansson')\n",
      "('Albert', 'Nolte')\n",
      "('Alec', 'Wayne')\n",
      "('Angela', 'Witherspoon')\n",
      "('Angela', 'Hudson')\n",
      "('Angelina', 'Astaire')\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "# Connect to the database and execute a query\n",
    "with engine.connect() as connection:\n",
    "    query = text(\"SELECT first_name, last_name from actor order by first_name limit 10\")  # Replace \"your_table\" with the actual table name\n",
    "    result = connection.execute(query).fetchall()  # Execute the query\n",
    "    for row in result:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb8d786",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgapic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PredictionServiceClient\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform_v1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PredictRequest\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the Prediction client\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m aiplatform_version\n\u001b[0;32m     21\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m aiplatform_version\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializer\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     ImageDataset,\n\u001b[0;32m     28\u001b[0m     TabularDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     VideoDataset,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform\\initializer.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterator, List, Optional, Type, TypeVar, Union\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m client_options\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gapic_v1\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m credentials \u001b[38;5;28;01mas\u001b[39;00m auth_credentials\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\api_core\\gapic_v1\\__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2017 Google LLC\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgapic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m client_info\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgapic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgapic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_async\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgapic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m method\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\api_core\\gapic_v1\\config.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m retry\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timeout\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\api_core\\exceptions.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrpc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m error_details_pb2\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgrpc\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\rpc\\error_details_pb2.py:52\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m duration_pb2 \u001b[38;5;28;01mas\u001b[39;00m google_dot_protobuf_dot_duration__pb2\n\u001b[0;32m     33\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     34\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/rpc/error_details.proto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m     package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle.rpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     dependencies\u001b[38;5;241m=\u001b[39m[google_dot_protobuf_dot_duration__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR],\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     44\u001b[0m _RETRYINFO \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     45\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle.rpc.RetryInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m     file\u001b[38;5;241m=\u001b[39mDESCRIPTOR,\n\u001b[0;32m     49\u001b[0m     containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m     create_key\u001b[38;5;241m=\u001b[39m_descriptor\u001b[38;5;241m.\u001b[39m_internal_create_key,\n\u001b[0;32m     51\u001b[0m     fields\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m---> 52\u001b[0m         \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFieldDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mretry_delay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoogle.rpc.RetryInfo.retry_delay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcpp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhas_default_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43menum_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontaining_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextension_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDESCRIPTOR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcreate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_create_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     ],\n\u001b[0;32m     72\u001b[0m     extensions\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     73\u001b[0m     nested_types\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     74\u001b[0m     enum_types\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     75\u001b[0m     serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m     is_extendable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m     syntax\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     extension_ranges\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     79\u001b[0m     oneofs\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     80\u001b[0m     serialized_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m78\u001b[39m,\n\u001b[0;32m     81\u001b[0m     serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m137\u001b[39m,\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     85\u001b[0m _DEBUGINFO \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     86\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebugInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle.rpc.DebugInfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m189\u001b[39m,\n\u001b[0;32m    142\u001b[0m )\n\u001b[0;32m    145\u001b[0m _QUOTAFAILURE_VIOLATION \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m    146\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViolation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m     full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle.rpc.QuotaFailure.Violation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m     serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m312\u001b[39m,\n\u001b[0;32m    202\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\protobuf\\descriptor.py:553\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, full_name, index, number, \u001b[38;5;28mtype\u001b[39m, cpp_type, label,\n\u001b[0;32m    548\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[0;32m    549\u001b[0m             is_extension, extension_scope, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    550\u001b[0m             serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    551\u001b[0m             has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, containing_oneof\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    552\u001b[0m             file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m--> 553\u001b[0m   \u001b[43m_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_extension:\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _message\u001b[38;5;241m.\u001b[39mdefault_pool\u001b[38;5;241m.\u001b[39mFindExtensionByName(full_name)\n",
      "\u001b[1;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "from google.cloud.aiplatform.gapic import PredictionServiceClient\n",
    "from google.cloud.aiplatform_v1.types import PredictRequest\n",
    "\n",
    "# Initialize the Prediction client\n",
    "client = PredictionServiceClient()\n",
    "\n",
    "# Define the model endpoint\n",
    "endpoint = client.endpoint_path(project=\"ordinal-city-425315-r1\", location=\"us-central1\", endpoint=\"\")\n",
    "\n",
    "# Define a function to query data and use the model for predictions\n",
    "def query_and_predict():\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(\"SELECT first_name, last_name from actor order by first_name limit 10\").fetchall()\n",
    "        for row in result:\n",
    "            text = f\"{row[0]} {row[1]}\"\n",
    "            # Prepare the request\n",
    "            instances = [{\"content\": text}]\n",
    "            request = PredictRequest(endpoint=endpoint, instances=instances)\n",
    "            # Get prediction\n",
    "            response = client.predict(request=request)\n",
    "            print(f\"Input Text: {text}\")\n",
    "            print(f\"Prediction: {response.predictions}\")\n",
    "\n",
    "# Call the function\n",
    "query_and_predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f24e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e327d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A code to connect to a PostgreSQL database, retrieves data, and uses Vertex AI to make predictions \n",
    "# without training a model or pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c641d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying without using any trained or pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f74347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a code to take a user NLP input and based on the intent give the DVD the person rented \n",
    "# (The input to give should be like \"What film did Adam Hopper rent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25402f65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (2.0.30)\n",
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.9-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from sqlalchemy) (4.12.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.9\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy psycopg2-binary scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d337f84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the NLP query: What film did  Bela Walken rent?\n",
      "\n",
      "Output:\n",
      "          title\n",
      "0  Carrie Bunch\n"
     ]
    }
   ],
   "source": [
    "# the input to give should be like \"What film did Adam Hopper rent?\"\n",
    "\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "# Function to query data from PostgreSQL\n",
    "def query_data(query):\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(query))\n",
    "        data = result.fetchall()\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "# Take user input for NLP query\n",
    "user_query = input(\"Enter the NLP query: \")\n",
    "\n",
    "# Understand the query and extract actor's first and last name\n",
    "actor_name = user_query.split(\"did \")[1].split(\" rent\")[0].split()\n",
    "\n",
    "# Construct the SQL query to find the film rented by the specified actor\n",
    "sql_query = f\"\"\"\n",
    "SELECT title \n",
    "FROM film \n",
    "WHERE film_id IN (\n",
    "    SELECT inventory.film_id \n",
    "    FROM inventory \n",
    "    JOIN rental ON inventory.inventory_id = rental.inventory_id \n",
    "    JOIN customer ON rental.customer_id = customer.customer_id \n",
    "    JOIN staff ON rental.staff_id = staff.staff_id \n",
    "    JOIN payment ON rental.rental_id = payment.rental_id\n",
    "    JOIN film_actor ON film_actor.film_id = inventory.film_id\n",
    "    JOIN actor ON film_actor.actor_id = actor.actor_id \n",
    "    WHERE actor.first_name = '{actor_name[0]}' AND actor.last_name = '{actor_name[1]}' \n",
    "    ORDER BY rental.rental_date DESC \n",
    "    LIMIT 1\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Retrieve data from PostgreSQL based on the query\n",
    "try:\n",
    "    data = query_data(sql_query)\n",
    "    if not data.empty:\n",
    "        print(\"\\nOutput:\")\n",
    "        print(data)\n",
    "    else:\n",
    "        print(\"\\nNo data found for the given query.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d056f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e0aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the above code but with any input i.e, not having any specific input like 'did' or 'rent'\n",
    "# i.e, Below is a code to take a user NLP input and based on the intent give the DVD the person rented \n",
    "# where the input does not need to have any specific input like 'did' or 'rent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17cbd577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.5-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "Collecting weasel<0.5.0,>=0.1.0\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (23.2)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp39-cp39-win_amd64.whl (25 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.7.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script pygmentize.exe is installed in 'C:\\Users\\adity\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'C:\\Users\\adity\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script typer.exe is installed in 'C:\\Users\\adity\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script weasel.exe is installed in 'C:\\Users\\adity\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script spacy.exe is installed in 'C:\\Users\\adity\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "jupyter-server 1.13.5 requires pywinpty<2; os_name == \"nt\", but you have pywinpty 2.0.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0\n",
      "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp39-cp39-win_amd64.whl (483 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Collecting thinc<8.3.0,>=8.2.2\n",
      "  Downloading thinc-8.2.4-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp39-cp39-win_amd64.whl (122 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Collecting language-data>=1.2\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "Collecting marisa-trie>=0.7.7\n",
      "  Downloading marisa_trie-1.2.0-cp39-cp39-win_amd64.whl (152 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp39-cp39-win_amd64.whl (6.6 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: mdurl, pygments, markdown-it-py, colorama, catalogue, srsly, shellingham, rich, murmurhash, marisa-trie, cymem, wasabi, typer, smart-open, preshed, language-data, confection, cloudpathlib, blis, weasel, thinc, spacy-loggers, spacy-legacy, langcodes, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.18.1 colorama-0.4.6 confection-0.1.5 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.2.0 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.10 preshed-3.0.9 pygments-2.18.0 rich-13.7.1 shellingham-1.5.4 smart-open-7.0.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.4 typer-0.12.3 wasabi-1.1.3 weasel-0.4.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.21.5)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (61.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efd5f092",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query in NLP : what was rented by Bela Walken recently ?\n",
      "\n",
      "Output:\n",
      "          title\n",
      "0  Carrie Bunch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "# Function to query data from PostgreSQL\n",
    "def query_data(query):\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(query))\n",
    "        data = result.fetchall()\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "# Function to extract actor's name from user query using SpaCy \n",
    "def extract_actor_name(user_query):\n",
    "    doc = nlp(user_query)\n",
    "    actor_name = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    if len(actor_name) == 0:\n",
    "        raise ValueError(\"Unable to extract actor's name from the given query.\")\n",
    "    return actor_name\n",
    "\n",
    "# Take user input for NLP query\n",
    "user_query = input(\"Enter the query in NLP : \")\n",
    "\n",
    "try:\n",
    "    # Extract actor's name\n",
    "    actor_names = extract_actor_name(user_query)\n",
    "    # print(f\"Extracted actor names: {actor_names}\")\n",
    "\n",
    "    # Assume the full name is in the format \"First Middle Last\" or \"First Last\"\n",
    "    if len(actor_names) == 1:\n",
    "        name_parts = actor_names[0].split()\n",
    "        if len(name_parts) == 2:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = name_parts[1]\n",
    "            name_condition = f\"actor.first_name = '{first_name}' AND actor.last_name = '{last_name}'\"\n",
    "        elif len(name_parts) > 2:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = name_parts[-1]\n",
    "            name_condition = f\"actor.first_name = '{first_name}' AND actor.last_name = '{last_name}'\"\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected name format extracted.\")\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected number of names extracted.\")\n",
    "\n",
    "    sql_query = f\"\"\"\n",
    "    SELECT title \n",
    "    FROM film \n",
    "    WHERE film_id IN (\n",
    "        SELECT inventory.film_id \n",
    "        FROM inventory \n",
    "        JOIN rental ON inventory.inventory_id = rental.inventory_id \n",
    "        JOIN customer ON rental.customer_id = customer.customer_id \n",
    "        JOIN staff ON rental.staff_id = staff.staff_id \n",
    "        JOIN payment ON rental.rental_id = payment.rental_id\n",
    "        JOIN film_actor ON film_actor.film_id = inventory.film_id\n",
    "        JOIN actor ON film_actor.actor_id = actor.actor_id \n",
    "        WHERE {name_condition}\n",
    "        ORDER BY rental.rental_date DESC \n",
    "        LIMIT 1\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    # print(f\"Constructed SQL Query: {sql_query}\")\n",
    "\n",
    "    # Retrieve data from PostgreSQL based on the query\n",
    "    data = query_data(sql_query)\n",
    "    if not data.empty:\n",
    "        print(\"\\nOutput:\")\n",
    "        print(data)\n",
    "    else:\n",
    "        print(\"\\nNo data found for the given query.\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Error: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# what was rented by Bela Walken recently ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c18f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "582d765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying the above code but with multiple names which needs to be extracted \n",
    "# i.e, Below is a code to take a user NLP input and based on the intent give the DVD the person rented \n",
    "# where the input can have multiple names in the input and we need to extract them and give the desired output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1079ea1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (3.7.5)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.7.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.1)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (61.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.21.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2021.10.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install aspacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d93aa3d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query in NLP: what was rented by Adam Grant and Bela Walken ?\n",
      "\n",
      "Output:\n",
      "                    title\n",
      "0              Luke Mummy\n",
      "1        Fantasy Troopers\n",
      "2     Operation Operation\n",
      "3         Groundhog Uncut\n",
      "4           Jacket Frisco\n",
      "5          Annie Identity\n",
      "6           Wanda Chamber\n",
      "7        Happiness United\n",
      "8       Midnight Westward\n",
      "9           Clerks Angels\n",
      "10          Loser Hustler\n",
      "11       Tycoon Gathering\n",
      "12          Nash Chocolat\n",
      "13          Pizza Jumanji\n",
      "14      Vertigo Northwest\n",
      "15   Ballroom Mockingbird\n",
      "16      Legally Secretary\n",
      "17              Trap Guys\n",
      "18     Beethoven Exorcist\n",
      "19        Splendor Patton\n",
      "20    Snatchers Montezuma\n",
      "21          Mod Secretary\n",
      "22  Flintstones Happiness\n",
      "23  Fireball Philadelphia\n",
      "24         Element Freddy\n",
      "25        Seabiscuit Punk\n",
      "26    Hollywood Anonymous\n",
      "27            Mighty Luck\n",
      "28           Carrie Bunch\n",
      "29            Glory Tracy\n",
      "30             Enemy Odds\n",
      "31            Stage World\n",
      "32        Twisted Pirates\n",
      "33            Siege Madre\n",
      "34           Tramp Others\n",
      "35          Jerk Paycheck\n",
      "36             Mars Roman\n",
      "37        Disciple Mother\n",
      "38       Oklahoma Jumanji\n",
      "39        Whisperer Giant\n",
      "40          Comforts Rush\n",
      "41        Idols Snatchers\n",
      "42    Midsummer Groundhog\n",
      "43             Lion Uncut\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "# Function to query data from PostgreSQL\n",
    "def query_data(query):\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(query))\n",
    "        data = result.fetchall()\n",
    "        return pd.DataFrame(data, columns=result.keys())\n",
    "\n",
    "# Function to extract actor's names from user query using SpaCy \n",
    "def extract_actor_names(user_query):\n",
    "    doc = nlp(user_query)\n",
    "    actor_names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    if len(actor_names) == 0:\n",
    "        raise ValueError(\"Unable to extract actor's name from the given query.\")\n",
    "    return actor_names\n",
    "\n",
    "# Take user input for NLP query\n",
    "user_query = input(\"Enter the query in NLP: \")\n",
    "\n",
    "try:\n",
    "    # Extract actor's names\n",
    "    actor_names = extract_actor_names(user_query)\n",
    "    \n",
    "    subqueries = []\n",
    "    for actor_name in actor_names:\n",
    "        name_parts = actor_name.split()\n",
    "        if len(name_parts) == 2:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = name_parts[1]\n",
    "        elif len(name_parts) > 2:\n",
    "            first_name = name_parts[0]\n",
    "            last_name = name_parts[-1]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected name format extracted.\")\n",
    "        \n",
    "        subquery = f\"\"\"\n",
    "        SELECT title \n",
    "        FROM film\n",
    "        WHERE film_id IN (\n",
    "            SELECT inventory.film_id\n",
    "            FROM inventory \n",
    "            JOIN rental ON inventory.inventory_id = rental.inventory_id \n",
    "            JOIN customer ON rental.customer_id = customer.customer_id \n",
    "            JOIN staff ON rental.staff_id = staff.staff_id \n",
    "            JOIN payment ON rental.rental_id = payment.rental_id\n",
    "            JOIN film_actor ON film_actor.film_id = inventory.film_id\n",
    "            JOIN actor ON film_actor.actor_id = actor.actor_id \n",
    "            WHERE actor.first_name = '{first_name}' AND actor.last_name = '{last_name}'\n",
    "        )\n",
    "        \"\"\"\n",
    "        subqueries.append(subquery)\n",
    "    \n",
    "    # Combine subqueries to get films rented by each actor\n",
    "    sql_query = \" UNION \".join(subqueries)\n",
    "\n",
    "    # Retrieve data from PostgreSQL based on the query\n",
    "    data = query_data(sql_query)\n",
    "    if not data.empty:\n",
    "        print(\"\\nOutput:\")\n",
    "        print(data)\n",
    "    else:\n",
    "        print(\"\\nNo data found for the given query.\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Error: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what was rented by Adam Grant and Bela Walken ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da255fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a code to take a user NLP input and based on the intent give the desired output, where the input can be \n",
    "# anything and the chatbot must identify what it is and give the output accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fa41b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question: what actor was in the DVD rented by Adam Grant ?\n",
      "  first_name             last_update  actor_id last_name\n",
      "0       Adam 2013-05-26 14:47:57.620        71     Grant\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Date, Float\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base, relationship\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the base for ORM models\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define ORM models for the tables\n",
    "class Customer(Base):\n",
    "    __tablename__ = 'customer'\n",
    "    customer_id = Column(Integer, primary_key=True)\n",
    "    store_id = Column(Integer)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    email = Column(String)\n",
    "    address_id = Column(Integer)\n",
    "    activebool = Column(Integer)\n",
    "    create_date = Column(Date)\n",
    "    last_update = Column(Date)\n",
    "    active = Column(Integer)\n",
    "\n",
    "class Film(Base):\n",
    "    __tablename__ = 'film'\n",
    "    film_id = Column(Integer, primary_key=True)\n",
    "    title = Column(String)\n",
    "    description = Column(String)\n",
    "    release_year = Column(Integer)\n",
    "    language_id = Column(Integer)\n",
    "    original_language_id = Column(Integer)\n",
    "    rental_duration = Column(Integer)\n",
    "    rental_rate = Column(Float)\n",
    "    length = Column(Integer)\n",
    "    replacement_cost = Column(Float)\n",
    "    rating = Column(String)\n",
    "    last_update = Column(Date)\n",
    "    special_features = Column(String)\n",
    "    fulltext = Column(String)\n",
    "\n",
    "class Actor(Base):\n",
    "    __tablename__ = 'actor'\n",
    "    actor_id = Column(Integer, primary_key=True)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Payment(Base):\n",
    "    __tablename__ = 'payment'\n",
    "    payment_id = Column(Integer, primary_key=True)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    staff_id = Column(Integer)\n",
    "    rental_id = Column(Integer)\n",
    "    amount = Column(Float)\n",
    "    payment_date = Column(Date)\n",
    "\n",
    "class Address(Base):\n",
    "    __tablename__ = 'address'\n",
    "    address_id = Column(Integer, primary_key=True)\n",
    "    address = Column(String)\n",
    "    address2 = Column(String)\n",
    "    district = Column(String)\n",
    "    city_id = Column(Integer)\n",
    "    postal_code = Column(String)\n",
    "    phone = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Rental(Base):\n",
    "    __tablename__ = 'rental'\n",
    "    rental_id = Column(Integer, primary_key=True)\n",
    "    rental_date = Column(Date)\n",
    "    inventory_id = Column(Integer)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    return_date = Column(Date)\n",
    "    staff_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Inventory(Base):\n",
    "    __tablename__ = 'inventory'\n",
    "    inventory_id = Column(Integer, primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'))\n",
    "    store_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class FilmActor(Base):\n",
    "    __tablename__ = 'film_actor'\n",
    "    actor_id = Column(Integer, ForeignKey('actor.actor_id'), primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'), primary_key=True)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Function to handle user NLP query and generate ORM queries dynamically\n",
    "def answer_question(user_query):\n",
    "    # Extract entities and keywords from user query using SpaCy\n",
    "    doc = nlp(user_query)\n",
    "    \n",
    "    # Initialize variables\n",
    "    table_name = None\n",
    "    conditions = {}\n",
    "    customer_name = None\n",
    "\n",
    "    # Define a mapping of keywords to ORM models and relevant columns\n",
    "    table_mapping = {\n",
    "        'customer': Customer,\n",
    "        'actor': Actor,\n",
    "        'film': Film,\n",
    "        'payment': Payment,\n",
    "        'address': Address,\n",
    "        'rental': Rental,\n",
    "        'inventory': Inventory,\n",
    "    }\n",
    "\n",
    "    # Extract keywords and entities to identify the table and conditions\n",
    "    for token in doc:\n",
    "        if token.lemma_.lower() in table_mapping:\n",
    "            table_name = token.lemma_.lower()\n",
    "            break\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            customer_name = ent.text\n",
    "            conditions['first_name'] = ent.text.split()[0]\n",
    "            if len(ent.text.split()) > 1:\n",
    "                conditions['last_name'] = ent.text.split()[1]\n",
    "\n",
    "    if 'rental' in user_query.lower() and customer_name:\n",
    "        # Handle specific case for rentals by a specific customer\n",
    "        rentals = session.query(Film.title).\\\n",
    "            join(Inventory, Film.film_id == Inventory.film_id).\\\n",
    "            join(Rental, Inventory.inventory_id == Rental.inventory_id).\\\n",
    "            join(Customer, Rental.customer_id == Customer.customer_id).\\\n",
    "            filter(Customer.first_name == conditions['first_name'],\n",
    "                   Customer.last_name == conditions['last_name']).all()\n",
    "        if rentals:\n",
    "            return pd.DataFrame(rentals, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'film' in user_query.lower() and 'director' in user_query.lower():\n",
    "        director_name = customer_name\n",
    "        director_first_name = director_name.split()[0]\n",
    "        director_last_name = director_name.split()[1] if len(director_name.split()) > 1 else ''\n",
    "        \n",
    "        films = session.query(Film.title).\\\n",
    "            join(FilmActor, Film.film_id == FilmActor.film_id).\\\n",
    "            join(Actor, FilmActor.actor_id == Actor.actor_id).\\\n",
    "            filter(Actor.first_name == director_first_name,\n",
    "                   Actor.last_name == director_last_name).all()\n",
    "        if films:\n",
    "            return pd.DataFrame(films, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if table_name is None:\n",
    "        return \"Sorry, I couldn't understand the question or it's not related to the available tables.\"\n",
    "\n",
    "    # Generate ORM query based on the identified table and additional conditions, if any\n",
    "    table_model = table_mapping[table_name]\n",
    "    query = session.query(table_model)\n",
    "\n",
    "    for key, value in conditions.items():\n",
    "        if hasattr(table_model, key):\n",
    "            query = query.filter(getattr(table_model, key) == value)\n",
    "\n",
    "    # Execute the ORM query and retrieve the data\n",
    "    try:\n",
    "        data = query.all()\n",
    "        if not data:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "        else:\n",
    "            return pd.DataFrame([d.__dict__ for d in data]).drop('_sa_instance_state', axis=1)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Take user input for NLP query\n",
    "user_query = input(\"Enter your question: \")\n",
    "\n",
    "# Answer the user query\n",
    "result = answer_question(user_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8690b419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question: What actor was in the DVD rented by Adam Grant?\n",
      "   actor_id first_name last_name             last_update\n",
      "0        71       Adam     Grant 2013-05-26 14:47:57.620\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Date, Float\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base, relationship\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the base for ORM models\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define ORM models for the tables\n",
    "class Customer(Base):\n",
    "    __tablename__ = 'customer'\n",
    "    customer_id = Column(Integer, primary_key=True)\n",
    "    store_id = Column(Integer)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    email = Column(String)\n",
    "    address_id = Column(Integer)\n",
    "    activebool = Column(Integer)\n",
    "    create_date = Column(Date)\n",
    "    last_update = Column(Date)\n",
    "    active = Column(Integer)\n",
    "\n",
    "class Film(Base):\n",
    "    __tablename__ = 'film'\n",
    "    film_id = Column(Integer, primary_key=True)\n",
    "    title = Column(String)\n",
    "    description = Column(String)\n",
    "    release_year = Column(Integer)\n",
    "    language_id = Column(Integer)\n",
    "    rental_duration = Column(Integer)\n",
    "    rental_rate = Column(Float)\n",
    "    length = Column(Integer)\n",
    "    replacement_cost = Column(Float)\n",
    "    rating = Column(String)\n",
    "    last_update = Column(Date)\n",
    "    special_features = Column(String)\n",
    "    fulltext = Column(String)\n",
    "\n",
    "class Actor(Base):\n",
    "    __tablename__ = 'actor'\n",
    "    actor_id = Column(Integer, primary_key=True)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Payment(Base):\n",
    "    __tablename__ = 'payment'\n",
    "    payment_id = Column(Integer, primary_key=True)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    staff_id = Column(Integer)\n",
    "    rental_id = Column(Integer)\n",
    "    amount = Column(Float)\n",
    "    payment_date = Column(Date)\n",
    "\n",
    "class Address(Base):\n",
    "    __tablename__ = 'address'\n",
    "    address_id = Column(Integer, primary_key=True)\n",
    "    address = Column(String)\n",
    "    address2 = Column(String)\n",
    "    district = Column(String)\n",
    "    city_id = Column(Integer)\n",
    "    postal_code = Column(String)\n",
    "    phone = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Rental(Base):\n",
    "    __tablename__ = 'rental'\n",
    "    rental_id = Column(Integer, primary_key=True)\n",
    "    rental_date = Column(Date)\n",
    "    inventory_id = Column(Integer)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    return_date = Column(Date)\n",
    "    staff_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Inventory(Base):\n",
    "    __tablename__ = 'inventory'\n",
    "    inventory_id = Column(Integer, primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'))\n",
    "    store_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class FilmActor(Base):\n",
    "    __tablename__ = 'film_actor'\n",
    "    actor_id = Column(Integer, ForeignKey('actor.actor_id'), primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'), primary_key=True)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Function to handle user NLP query and generate ORM queries dynamically\n",
    "def answer_question(user_query):\n",
    "    # Extract entities and keywords from user query using SpaCy\n",
    "    doc = nlp(user_query)\n",
    "    \n",
    "    # Initialize variables\n",
    "    table_name = None\n",
    "    conditions = {}\n",
    "    customer_name = None\n",
    "    actor_name = None\n",
    "    director_name = None\n",
    "\n",
    "    # Define a mapping of keywords to ORM models and relevant columns\n",
    "    table_mapping = {\n",
    "        'customer': Customer,\n",
    "        'actor': Actor,\n",
    "        'film': Film,\n",
    "        'payment': Payment,\n",
    "        'address': Address,\n",
    "        'rental': Rental,\n",
    "        'inventory': Inventory,\n",
    "    }\n",
    "\n",
    "    # Extract keywords and entities to identify the table and conditions\n",
    "    for token in doc:\n",
    "        if token.lemma_.lower() in table_mapping:\n",
    "            table_name = token.lemma_.lower()\n",
    "            break\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            name_parts = ent.text.split()\n",
    "            if 'rental' in user_query.lower() or 'customer' in user_query.lower():\n",
    "                customer_name = ent.text\n",
    "                conditions['first_name'] = name_parts[0]\n",
    "                if len(name_parts) > 1:\n",
    "                    conditions['last_name'] = name_parts[1]\n",
    "            elif 'actor' in user_query.lower() or 'director' in user_query.lower():\n",
    "                actor_name = ent.text\n",
    "                conditions['first_name'] = name_parts[0]\n",
    "                if len(name_parts) > 1:\n",
    "                    conditions['last_name'] = name_parts[1]\n",
    "\n",
    "    if 'rented by' in user_query.lower() and customer_name:\n",
    "        # Handle specific case for rentals by a specific customer\n",
    "        rentals = session.query(Film.title).\\\n",
    "            join(Inventory, Film.film_id == Inventory.film_id).\\\n",
    "            join(Rental, Inventory.inventory_id == Rental.inventory_id).\\\n",
    "            join(Customer, Rental.customer_id == Customer.customer_id).\\\n",
    "            filter(Customer.first_name == conditions['first_name'],\n",
    "                   Customer.last_name == conditions['last_name']).all()\n",
    "        if rentals:\n",
    "            return pd.DataFrame(rentals, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'films directed by' in user_query.lower() and actor_name:\n",
    "        # Handle specific case for films directed by a specific director\n",
    "        films = session.query(Film.title).\\\n",
    "            join(FilmActor, Film.film_id == FilmActor.film_id).\\\n",
    "            join(Actor, FilmActor.actor_id == Actor.actor_id).\\\n",
    "            filter(Actor.first_name == conditions['first_name'],\n",
    "                   Actor.last_name == conditions['last_name']).all()\n",
    "        if films:\n",
    "            return pd.DataFrame(films, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'actor in the DVD rented by' in user_query.lower() and customer_name:\n",
    "        # Handle specific case for actors in DVDs rented by a specific customer\n",
    "        actors = session.query(Actor.first_name, Actor.last_name).\\\n",
    "            join(FilmActor, Actor.actor_id == FilmActor.actor_id).\\\n",
    "            join(Inventory, FilmActor.film_id == Inventory.film_id).\\\n",
    "            join(Rental, Inventory.inventory_id == Rental.inventory_id).\\\n",
    "            join(Customer, Rental.customer_id == Customer.customer_id).\\\n",
    "            filter(Customer.first_name == conditions['first_name'],\n",
    "                   Customer.last_name == conditions['last_name']).all()\n",
    "        if actors:\n",
    "            return pd.DataFrame(actors, columns=['first_name', 'last_name'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if table_name is None:\n",
    "        return \"Sorry, I couldn't understand the question or it's not related to the available tables.\"\n",
    "\n",
    "    # Generate ORM query based on the identified table and additional conditions, if any\n",
    "    table_model = table_mapping[table_name]\n",
    "    query = session.query(table_model)\n",
    "\n",
    "    for key, value in conditions.items():\n",
    "        if hasattr(table_model, key):\n",
    "            query = query.filter(getattr(table_model, key) == value)\n",
    "\n",
    "    # Execute the ORM query and retrieve the data\n",
    "    try:\n",
    "        data = query.all()\n",
    "        if not data:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "        else:\n",
    "            return pd.DataFrame([d.__dict__ for d in data]).drop('_sa_instance_state', axis=1)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Take user input for NLP query\n",
    "user_query = input(\"Enter your question: \")\n",
    "\n",
    "# Answer the user query\n",
    "result = answer_question(user_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6bb3f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question: Show me films directed by Quentin Tarantino\n",
      "Extracted name: {'first_name': 'Quentin', 'last_name': 'Tarantino'}\n",
      "Querying films directed by: Quentin Tarantino\n",
      "Films found: []\n",
      "No data found for the given query: Show me films directed by Quentin Tarantino\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Date, Float\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base, relationship\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the base for ORM models\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define ORM models for the tables\n",
    "class Customer(Base):\n",
    "    __tablename__ = 'customer'\n",
    "    customer_id = Column(Integer, primary_key=True)\n",
    "    store_id = Column(Integer)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    email = Column(String)\n",
    "    address_id = Column(Integer)\n",
    "    activebool = Column(Integer)\n",
    "    create_date = Column(Date)\n",
    "    last_update = Column(Date)\n",
    "    active = Column(Integer)\n",
    "\n",
    "class Film(Base):\n",
    "    __tablename__ = 'film'\n",
    "    film_id = Column(Integer, primary_key=True)\n",
    "    title = Column(String)\n",
    "    description = Column(String)\n",
    "    release_year = Column(Integer)\n",
    "    language_id = Column(Integer)\n",
    "    rental_duration = Column(Integer)\n",
    "    rental_rate = Column(Float)\n",
    "    length = Column(Integer)\n",
    "    replacement_cost = Column(Float)\n",
    "    rating = Column(String)\n",
    "    last_update = Column(Date)\n",
    "    special_features = Column(String)\n",
    "    fulltext = Column(String)\n",
    "\n",
    "class Actor(Base):\n",
    "    __tablename__ = 'actor'\n",
    "    actor_id = Column(Integer, primary_key=True)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Payment(Base):\n",
    "    __tablename__ = 'payment'\n",
    "    payment_id = Column(Integer, primary_key=True)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    staff_id = Column(Integer)\n",
    "    rental_id = Column(Integer)\n",
    "    amount = Column(Float)\n",
    "    payment_date = Column(Date)\n",
    "\n",
    "class Address(Base):\n",
    "    __tablename__ = 'address'\n",
    "    address_id = Column(Integer, primary_key=True)\n",
    "    address = Column(String)\n",
    "    address2 = Column(String)\n",
    "    district = Column(String)\n",
    "    city_id = Column(Integer)\n",
    "    postal_code = Column(String)\n",
    "    phone = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Rental(Base):\n",
    "    __tablename__ = 'rental'\n",
    "    rental_id = Column(Integer, primary_key=True)\n",
    "    rental_date = Column(Date)\n",
    "    inventory_id = Column(Integer)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    return_date = Column(Date)\n",
    "    staff_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Inventory(Base):\n",
    "    __tablename__ = 'inventory'\n",
    "    inventory_id = Column(Integer, primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'))\n",
    "    store_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class FilmActor(Base):\n",
    "    __tablename__ = 'film_actor'\n",
    "    actor_id = Column(Integer, ForeignKey('actor.actor_id'), primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'), primary_key=True)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Function to handle user NLP query and generate ORM queries dynamically\n",
    "def answer_question(user_query):\n",
    "    # Extract entities and keywords from user query using SpaCy\n",
    "    doc = nlp(user_query)\n",
    "    \n",
    "    # Initialize variables\n",
    "    conditions = {}\n",
    "    customer_name = None\n",
    "    actor_name = None\n",
    "\n",
    "    # Define a mapping of keywords to ORM models and relevant columns\n",
    "    table_mapping = {\n",
    "        'customer': Customer,\n",
    "        'actor': Actor,\n",
    "        'film': Film,\n",
    "        'payment': Payment,\n",
    "        'address': Address,\n",
    "        'rental': Rental,\n",
    "        'inventory': Inventory,\n",
    "    }\n",
    "\n",
    "    # Extract keywords and entities to identify the table and conditions\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            name_parts = ent.text.split()\n",
    "            conditions['first_name'] = name_parts[0]\n",
    "            if len(name_parts) > 1:\n",
    "                conditions['last_name'] = name_parts[1]\n",
    "            print(f\"Extracted name: {conditions}\")  # Debugging\n",
    "\n",
    "    if 'rented by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for rentals by a specific customer\n",
    "        customer_first_name = conditions['first_name']\n",
    "        customer_last_name = conditions.get('last_name', '')\n",
    "        print(f\"Querying rentals for: {customer_first_name} {customer_last_name}\")  # Debugging\n",
    "        rentals = session.query(Film.title).\\\n",
    "            join(Inventory, Film.film_id == Inventory.film_id).\\\n",
    "            join(Rental, Inventory.inventory_id == Rental.inventory_id).\\\n",
    "            join(Customer, Rental.customer_id == Customer.customer_id).\\\n",
    "            filter(Customer.first_name == customer_first_name,\n",
    "                   Customer.last_name == customer_last_name).all()\n",
    "        print(f\"Rentals found: {rentals}\")  # Debugging\n",
    "        if rentals:\n",
    "            return pd.DataFrame(rentals, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'films directed by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for films directed by a specific director\n",
    "        actor_first_name = conditions['first_name']\n",
    "        actor_last_name = conditions.get('last_name', '')\n",
    "        print(f\"Querying films directed by: {actor_first_name} {actor_last_name}\")  # Debugging\n",
    "        films = session.query(Film.title).\\\n",
    "            join(FilmActor, Film.film_id == FilmActor.film_id).\\\n",
    "            join(Actor, FilmActor.actor_id == Actor.actor_id).\\\n",
    "            filter(Actor.first_name == actor_first_name,\n",
    "                   Actor.last_name == actor_last_name).all()\n",
    "        print(f\"Films found: {films}\")  # Debugging\n",
    "        if films:\n",
    "            return pd.DataFrame(films, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'actor in the DVD rented by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for actors in DVDs rented by a specific customer\n",
    "        customer_first_name = conditions['first_name']\n",
    "        customer_last_name = conditions.get('last_name', '')\n",
    "        print(f\"Querying actors in DVDs rented by: {customer_first_name} {customer_last_name}\")  # Debugging\n",
    "        actors = session.query(Actor.first_name, Actor.last_name).\\\n",
    "            join(FilmActor, Actor.actor_id == FilmActor.actor_id).\\\n",
    "            join(Inventory, FilmActor.film_id == Inventory.film_id).\\\n",
    "            join(Rental, Inventory.inventory_id == Rental.inventory_id).\\\n",
    "            join(Customer, Rental.customer_id == Customer.customer_id).\\\n",
    "            filter(Customer.first_name == customer_first_name,\n",
    "                   Customer.last_name == customer_last_name).all()\n",
    "        print(f\"Actors found: {actors}\")  # Debugging\n",
    "        if actors:\n",
    "            return pd.DataFrame(actors, columns=['first_name', 'last_name'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    return \"Sorry, I couldn't understand the question or it's not related to the available tables.\"\n",
    "\n",
    "# Take user input for NLP query\n",
    "user_query = input(\"Enter your question: \")\n",
    "\n",
    "# Answer the user query\n",
    "result = answer_question(user_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f89ea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question: What was rented by Adam Grant?\n",
      "Extracted name: {'first_name': 'Adam', 'last_name': 'Grant'}\n",
      "Executing SQL Query: \n",
      "        SELECT title \n",
      "        FROM film \n",
      "        WHERE film_id IN (\n",
      "            SELECT inventory.film_id \n",
      "            FROM inventory \n",
      "            JOIN rental ON inventory.inventory_id = rental.inventory_id \n",
      "            JOIN customer ON rental.customer_id = customer.customer_id \n",
      "            WHERE customer.first_name = 'Adam' AND customer.last_name = 'Grant'\n",
      "        )\n",
      "        \n",
      "No data found for the given query: What was rented by Adam Grant?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Date, Float, text\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base, relationship\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the base for ORM models\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define ORM models for the tables\n",
    "class Customer(Base):\n",
    "    __tablename__ = 'customer'\n",
    "    customer_id = Column(Integer, primary_key=True)\n",
    "    store_id = Column(Integer)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    email = Column(String)\n",
    "    address_id = Column(Integer)\n",
    "    activebool = Column(Integer)\n",
    "    create_date = Column(Date)\n",
    "    last_update = Column(Date)\n",
    "    active = Column(Integer)\n",
    "\n",
    "class Film(Base):\n",
    "    __tablename__ = 'film'\n",
    "    film_id = Column(Integer, primary_key=True)\n",
    "    title = Column(String)\n",
    "    description = Column(String)\n",
    "    release_year = Column(Integer)\n",
    "    language_id = Column(Integer)\n",
    "    rental_duration = Column(Integer)\n",
    "    rental_rate = Column(Float)\n",
    "    length = Column(Integer)\n",
    "    replacement_cost = Column(Float)\n",
    "    rating = Column(String)\n",
    "    last_update = Column(Date)\n",
    "    special_features = Column(String)\n",
    "    fulltext = Column(String)\n",
    "\n",
    "class Actor(Base):\n",
    "    __tablename__ = 'actor'\n",
    "    actor_id = Column(Integer, primary_key=True)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Payment(Base):\n",
    "    __tablename__ = 'payment'\n",
    "    payment_id = Column(Integer, primary_key=True)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    staff_id = Column(Integer)\n",
    "    rental_id = Column(Integer)\n",
    "    amount = Column(Float)\n",
    "    payment_date = Column(Date)\n",
    "\n",
    "class Address(Base):\n",
    "    __tablename__ = 'address'\n",
    "    address_id = Column(Integer, primary_key=True)\n",
    "    address = Column(String)\n",
    "    address2 = Column(String)\n",
    "    district = Column(String)\n",
    "    city_id = Column(Integer)\n",
    "    postal_code = Column(String)\n",
    "    phone = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Rental(Base):\n",
    "    __tablename__ = 'rental'\n",
    "    rental_id = Column(Integer, primary_key=True)\n",
    "    rental_date = Column(Date)\n",
    "    inventory_id = Column(Integer)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    return_date = Column(Date)\n",
    "    staff_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Inventory(Base):\n",
    "    __tablename__ = 'inventory'\n",
    "    inventory_id = Column(Integer, primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'))\n",
    "    store_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class FilmActor(Base):\n",
    "    __tablename__ = 'film_actor'\n",
    "    actor_id = Column(Integer, ForeignKey('actor.actor_id'), primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'), primary_key=True)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Function to handle user NLP query and generate raw SQL queries dynamically\n",
    "def answer_question(user_query):\n",
    "    # Extract entities and keywords from user query using SpaCy\n",
    "    doc = nlp(user_query)\n",
    "    \n",
    "    # Initialize variables\n",
    "    conditions = {}\n",
    "    customer_name = None\n",
    "    actor_name = None\n",
    "\n",
    "    # Extract keywords and entities to identify the conditions\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            name_parts = ent.text.split()\n",
    "            conditions['first_name'] = name_parts[0]\n",
    "            if len(name_parts) > 1:\n",
    "                conditions['last_name'] = name_parts[1]\n",
    "            print(f\"Extracted name: {conditions}\")  # Debugging\n",
    "\n",
    "    if 'rented by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for rentals by a specific customer\n",
    "        customer_first_name = conditions['first_name']\n",
    "        customer_last_name = conditions.get('last_name', '')\n",
    "        name_condition = f\"customer.first_name = '{customer_first_name}' AND customer.last_name = '{customer_last_name}'\"\n",
    "        \n",
    "        sql_query = f\"\"\"\n",
    "        SELECT title \n",
    "        FROM film \n",
    "        WHERE film_id IN (\n",
    "            SELECT inventory.film_id \n",
    "            FROM inventory \n",
    "            JOIN rental ON inventory.inventory_id = rental.inventory_id \n",
    "            JOIN customer ON rental.customer_id = customer.customer_id \n",
    "            WHERE {name_condition}\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Executing SQL Query: {sql_query}\")  # Debugging\n",
    "        result = session.execute(text(sql_query)).fetchall()\n",
    "        if result:\n",
    "            return pd.DataFrame(result, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'films directed by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for films directed by a specific director\n",
    "        actor_first_name = conditions['first_name']\n",
    "        actor_last_name = conditions.get('last_name', '')\n",
    "        name_condition = f\"actor.first_name = '{actor_first_name}' AND actor.last_name = '{actor_last_name}'\"\n",
    "        \n",
    "        sql_query = f\"\"\"\n",
    "        SELECT title \n",
    "        FROM film \n",
    "        WHERE film_id IN (\n",
    "            SELECT inventory.film_id \n",
    "            FROM inventory \n",
    "            JOIN film_actor ON film_actor.film_id = inventory.film_id\n",
    "            JOIN actor ON film_actor.actor_id = actor.actor_id \n",
    "            WHERE {name_condition}\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Executing SQL Query: {sql_query}\")  # Debugging\n",
    "        result = session.execute(text(sql_query)).fetchall()\n",
    "        if result:\n",
    "            return pd.DataFrame(result, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'actor in the DVD rented by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for actors in DVDs rented by a specific customer\n",
    "        customer_first_name = conditions['first_name']\n",
    "        customer_last_name = conditions.get('last_name', '')\n",
    "        name_condition = f\"customer.first_name = '{customer_first_name}' AND customer.last_name = '{customer_last_name}'\"\n",
    "        \n",
    "        sql_query = f\"\"\"\n",
    "        SELECT actor.first_name, actor.last_name\n",
    "        FROM actor\n",
    "        WHERE actor_id IN (\n",
    "            SELECT film_actor.actor_id \n",
    "            FROM film_actor\n",
    "            JOIN inventory ON film_actor.film_id = inventory.film_id\n",
    "            JOIN rental ON inventory.inventory_id = rental.inventory_id\n",
    "            JOIN customer ON rental.customer_id = customer.customer_id\n",
    "            WHERE {name_condition}\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Executing SQL Query: {sql_query}\")  # Debugging\n",
    "        result = session.execute(text(sql_query)).fetchall()\n",
    "        if result:\n",
    "            return pd.DataFrame(result, columns=['first_name', 'last_name'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    return \"Sorry, I couldn't understand the question or it's not related to the available tables.\"\n",
    "\n",
    "# Take user input for NLP query\n",
    "user_query = input(\"Enter your question: \")\n",
    "\n",
    "# Answer the user query\n",
    "result = answer_question(user_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0447fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user NLP query \"Show me films directed by Quentin Tarantino\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-language\n",
    "!pip install google-cloud-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey, Date, Float\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base, relationship\n",
    "import pandas as pd\n",
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "\n",
    "# Define the base for ORM models\n",
    "Base = declarative_base()\n",
    "\n",
    "# Define ORM models for the tables\n",
    "class Customer(Base):\n",
    "    __tablename__ = 'customer'\n",
    "    customer_id = Column(Integer, primary_key=True)\n",
    "    store_id = Column(Integer)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    email = Column(String)\n",
    "    address_id = Column(Integer)\n",
    "    activebool = Column(Integer)\n",
    "    create_date = Column(Date)\n",
    "    last_update = Column(Date)\n",
    "    active = Column(Integer)\n",
    "\n",
    "class Film(Base):\n",
    "    __tablename__ = 'film'\n",
    "    film_id = Column(Integer, primary_key=True)\n",
    "    title = Column(String)\n",
    "    description = Column(String)\n",
    "    release_year = Column(Integer)\n",
    "    language_id = Column(Integer)\n",
    "    rental_duration = Column(Integer)\n",
    "    rental_rate = Column(Float)\n",
    "    length = Column(Integer)\n",
    "    replacement_cost = Column(Float)\n",
    "    rating = Column(String)\n",
    "    last_update = Column(Date)\n",
    "    special_features = Column(String)\n",
    "    fulltext = Column(String)\n",
    "\n",
    "class Actor(Base):\n",
    "    __tablename__ = 'actor'\n",
    "    actor_id = Column(Integer, primary_key=True)\n",
    "    first_name = Column(String)\n",
    "    last_name = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Payment(Base):\n",
    "    __tablename__ = 'payment'\n",
    "    payment_id = Column(Integer, primary_key=True)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    staff_id = Column(Integer)\n",
    "    rental_id = Column(Integer)\n",
    "    amount = Column(Float)\n",
    "    payment_date = Column(Date)\n",
    "\n",
    "class Address(Base):\n",
    "    __tablename__ = 'address'\n",
    "    address_id = Column(Integer, primary_key=True)\n",
    "    address = Column(String)\n",
    "    address2 = Column(String)\n",
    "    district = Column(String)\n",
    "    city_id = Column(Integer)\n",
    "    postal_code = Column(String)\n",
    "    phone = Column(String)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Rental(Base):\n",
    "    __tablename__ = 'rental'\n",
    "    rental_id = Column(Integer, primary_key=True)\n",
    "    rental_date = Column(Date)\n",
    "    inventory_id = Column(Integer)\n",
    "    customer_id = Column(Integer, ForeignKey('customer.customer_id'))\n",
    "    return_date = Column(Date)\n",
    "    staff_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class Inventory(Base):\n",
    "    __tablename__ = 'inventory'\n",
    "    inventory_id = Column(Integer, primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'))\n",
    "    store_id = Column(Integer)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "class FilmActor(Base):\n",
    "    __tablename__ = 'film_actor'\n",
    "    actor_id = Column(Integer, ForeignKey('actor.actor_id'), primary_key=True)\n",
    "    film_id = Column(Integer, ForeignKey('film.film_id'), primary_key=True)\n",
    "    last_update = Column(Date)\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = 'your_password'\n",
    "db_host = 'your_cloud_sql_ip'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Function to handle user NLP query and generate ORM queries dynamically\n",
    "def analyze_entities(text_content):\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    response = client.analyze_entities(document=document)\n",
    "\n",
    "    entities = {}\n",
    "    for entity in response.entities:\n",
    "        if enums.Entity.Type(entity.type).name == \"PERSON\":\n",
    "            entities['PERSON'] = entity.name\n",
    "        print(f\"Entity: {entity.name} Type: {enums.Entity.Type(entity.type).name}\")  # Debugging\n",
    "\n",
    "    return entities\n",
    "\n",
    "def answer_question(user_query):\n",
    "    # Extract entities using Google Cloud's Natural Language API\n",
    "    entities = analyze_entities(user_query)\n",
    "    \n",
    "    # Initialize variables\n",
    "    conditions = {}\n",
    "    customer_name = entities.get('PERSON')\n",
    "    if customer_name:\n",
    "        name_parts = customer_name.split()\n",
    "        conditions['first_name'] = name_parts[0]\n",
    "        if len(name_parts) > 1:\n",
    "            conditions['last_name'] = name_parts[1]\n",
    "        print(f\"Extracted name: {conditions}\")  # Debugging\n",
    "\n",
    "    if 'rented by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for rentals by a specific customer\n",
    "        customer_first_name = conditions['first_name']\n",
    "        customer_last_name = conditions.get('last_name', '')\n",
    "        print(f\"Querying rentals for: {customer_first_name} {customer_last_name}\")  # Debugging\n",
    "        rentals = session.query(Film.title).\\\n",
    "            join(Inventory, Film.film_id == Inventory.film_id).\\\n",
    "            join(Rental, Inventory.inventory_id == Rental.inventory_id).\\\n",
    "            join(Customer, Rental.customer_id == Customer.customer_id).\\\n",
    "            filter(Customer.first_name == customer_first_name,\n",
    "                   Customer.last_name == customer_last_name).all()\n",
    "        print(f\"Rentals found: {rentals}\")  # Debugging\n",
    "        if rentals:\n",
    "            return pd.DataFrame(rentals, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'films directed by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for films directed by a specific director\n",
    "        actor_first_name = conditions['first_name']\n",
    "        actor_last_name = conditions.get('last_name', '')\n",
    "        print(f\"Querying films directed by: {actor_first_name} {actor_last_name}\")  # Debugging\n",
    "        films = session.query(Film.title).\\\n",
    "            join(FilmActor, Film.film_id == FilmActor.film_id).\\\n",
    "            join(Actor, FilmActor.actor_id == Actor.actor_id).\\\n",
    "            filter(Actor.first_name == actor_first_name,\n",
    "                   Actor.last_name == actor_last_name).all()\n",
    "        print(f\"Films found: {films}\")  # Debugging\n",
    "        if films:\n",
    "            return pd.DataFrame(films, columns=['title'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    if 'actor in the DVD rented by' in user_query.lower() and 'first_name' in conditions:\n",
    "        # Handle specific case for actors in DVDs rented by a specific customer\n",
    "        customer_first_name = conditions['first_name']\n",
    "        customer_last_name = conditions.get('last_name', '')\n",
    "        print(f\"Querying actors in DVDs rented by: {customer_first_name} {customer_last_name}\")  # Debugging\n",
    "        actors = session.query(Actor.first_name, Actor.last_name).\\\n",
    "            join(FilmActor, Actor.actor_id == FilmActor.actor_id).\\\n",
    "            join(Inventory, FilmActor.film_id == Inventory.film_id).\\\n",
    "            join(Rental, Inventory.inventory_id == Rental.inventory_id).\\\n",
    "            join(Customer, Rental.customer_id == Customer.customer_id).\\\n",
    "            filter(Customer.first_name == customer_first_name,\n",
    "                   Customer.last_name == customer_last_name).all()\n",
    "        print(f\"Actors found: {actors}\")  # Debugging\n",
    "        if actors:\n",
    "            return pd.DataFrame(actors, columns=['first_name', 'last_name'])\n",
    "        else:\n",
    "            return f\"No data found for the given query: {user_query}\"\n",
    "\n",
    "    return \"Sorry, I couldn't understand the question or it's not related to the available tables.\"\n",
    "\n",
    "# Take user input for NLP query\n",
    "user_query = input(\"Enter your question: \")\n",
    "\n",
    "# Answer the user query\n",
    "result = answer_question(user_query)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1356562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a807cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Data for actor:\n",
      "     actor_id first_name     last_name             last_update\n",
      "0           1   Penelope       Guiness 2013-05-26 14:47:57.620\n",
      "1           2       Nick      Wahlberg 2013-05-26 14:47:57.620\n",
      "2           3         Ed         Chase 2013-05-26 14:47:57.620\n",
      "3           4   Jennifer         Davis 2013-05-26 14:47:57.620\n",
      "4           5     Johnny  Lollobrigida 2013-05-26 14:47:57.620\n",
      "..        ...        ...           ...                     ...\n",
      "195       196       Bela        Walken 2013-05-26 14:47:57.620\n",
      "196       197      Reese          West 2013-05-26 14:47:57.620\n",
      "197       198       Mary        Keitel 2013-05-26 14:47:57.620\n",
      "198       199      Julia       Fawcett 2013-05-26 14:47:57.620\n",
      "199       200      Thora        Temple 2013-05-26 14:47:57.620\n",
      "\n",
      "[200 rows x 4 columns]\n",
      "\n",
      "Retrieved Data for film:\n",
      "     film_id              title  \\\n",
      "0        133    Chamber Italian   \n",
      "1        384   Grosse Wonderful   \n",
      "2          8    Airport Pollock   \n",
      "3         98  Bright Encounters   \n",
      "4          1   Academy Dinosaur   \n",
      "..       ...                ...   \n",
      "995      996     Young Language   \n",
      "996      997         Youth Kick   \n",
      "997      998       Zhivago Core   \n",
      "998      999  Zoolander Fiction   \n",
      "999     1000          Zorro Ark   \n",
      "\n",
      "                                           description  release_year  \\\n",
      "0    A Fateful Reflection of a Moose And a Husband ...          2006   \n",
      "1    A Epic Drama of a Cat And a Explorer who must ...          2006   \n",
      "2    A Epic Tale of a Moose And a Girl who must Con...          2006   \n",
      "3    A Fateful Yarn of a Lumberjack And a Feminist ...          2006   \n",
      "4    A Epic Drama of a Feminist And a Mad Scientist...          2006   \n",
      "..                                                 ...           ...   \n",
      "995  A Unbelieveable Yarn of a Boat And a Database ...          2006   \n",
      "996  A Touching Drama of a Teacher And a Cat who mu...          2006   \n",
      "997  A Fateful Yarn of a Composer And a Man who mus...          2006   \n",
      "998  A Fateful Reflection of a Waitress And a Boat ...          2006   \n",
      "999  A Intrepid Panorama of a Mad Scientist And a B...          2006   \n",
      "\n",
      "     language_id  rental_duration rental_rate  length replacement_cost rating  \\\n",
      "0              1                7        4.99     117            14.99  NC-17   \n",
      "1              1                5        4.99      49            19.99      R   \n",
      "2              1                6        4.99      54            15.99      R   \n",
      "3              1                4        4.99      73            12.99  PG-13   \n",
      "4              1                6        0.99      86            20.99     PG   \n",
      "..           ...              ...         ...     ...              ...    ...   \n",
      "995            1                6        0.99     183             9.99      G   \n",
      "996            1                4        0.99     179            14.99  NC-17   \n",
      "997            1                6        0.99     105            10.99  NC-17   \n",
      "998            1                5        2.99     101            28.99      R   \n",
      "999            1                3        4.99      50            18.99  NC-17   \n",
      "\n",
      "                last_update                             special_features  \\\n",
      "0   2013-05-26 14:50:58.951                                   [Trailers]   \n",
      "1   2013-05-26 14:50:58.951                          [Behind the Scenes]   \n",
      "2   2013-05-26 14:50:58.951                                   [Trailers]   \n",
      "3   2013-05-26 14:50:58.951                                   [Trailers]   \n",
      "4   2013-05-26 14:50:58.951          [Deleted Scenes, Behind the Scenes]   \n",
      "..                      ...                                          ...   \n",
      "995 2013-05-26 14:50:58.951                [Trailers, Behind the Scenes]   \n",
      "996 2013-05-26 14:50:58.951                [Trailers, Behind the Scenes]   \n",
      "997 2013-05-26 14:50:58.951                             [Deleted Scenes]   \n",
      "998 2013-05-26 14:50:58.951                   [Trailers, Deleted Scenes]   \n",
      "999 2013-05-26 14:50:58.951  [Trailers, Commentaries, Behind the Scenes]   \n",
      "\n",
      "                                              fulltext  \n",
      "0    'chamber':1 'fate':4 'husband':11 'italian':2 ...  \n",
      "1    'australia':18 'cat':8 'drama':5 'epic':4 'exp...  \n",
      "2    'airport':1 'ancient':18 'confront':14 'epic':...  \n",
      "3    'boat':20 'bright':1 'conquer':14 'encount':2 ...  \n",
      "4    'academi':1 'battl':15 'canadian':20 'dinosaur...  \n",
      "..                                                 ...  \n",
      "995  'administr':12 'boat':8 'boy':17 'databas':11 ...  \n",
      "996  'boat':22 'cat':11 'challeng':14 'drama':5 'ki...  \n",
      "997  'boy':16 'canadian':19 'compos':8 'core':2 'fa...  \n",
      "998  'ancient':19 'boat':11 'china':20 'discov':14 ...  \n",
      "999  'ark':2 'boy':12,17 'intrepid':4 'mad':8 'mona...  \n",
      "\n",
      "[1000 rows x 13 columns]\n",
      "\n",
      "Retrieved Data for film_actor:\n",
      "      actor_id  film_id         last_update\n",
      "0            1        1 2006-02-15 10:05:03\n",
      "1            1       23 2006-02-15 10:05:03\n",
      "2            1       25 2006-02-15 10:05:03\n",
      "3            1      106 2006-02-15 10:05:03\n",
      "4            1      140 2006-02-15 10:05:03\n",
      "...        ...      ...                 ...\n",
      "5457       200      879 2006-02-15 10:05:03\n",
      "5458       200      912 2006-02-15 10:05:03\n",
      "5459       200      945 2006-02-15 10:05:03\n",
      "5460       200      958 2006-02-15 10:05:03\n",
      "5461       200      993 2006-02-15 10:05:03\n",
      "\n",
      "[5462 rows x 3 columns]\n",
      "\n",
      "Retrieved Data for customer:\n",
      "     customer_id  store_id first_name  last_name  \\\n",
      "0            524         1      Jared        Ely   \n",
      "1              1         1       Mary      Smith   \n",
      "2              2         1   Patricia    Johnson   \n",
      "3              3         1      Linda   Williams   \n",
      "4              4         2    Barbara      Jones   \n",
      "..           ...       ...        ...        ...   \n",
      "594          595         1   Terrence  Gunderson   \n",
      "595          596         1    Enrique   Forsythe   \n",
      "596          597         1    Freddie     Duggan   \n",
      "597          598         1       Wade   Delvalle   \n",
      "598          599         2     Austin    Cintron   \n",
      "\n",
      "                                     email  address_id  activebool  \\\n",
      "0             jared.ely@sakilacustomer.org         530        True   \n",
      "1            mary.smith@sakilacustomer.org           5        True   \n",
      "2      patricia.johnson@sakilacustomer.org           6        True   \n",
      "3        linda.williams@sakilacustomer.org           7        True   \n",
      "4         barbara.jones@sakilacustomer.org           8        True   \n",
      "..                                     ...         ...         ...   \n",
      "594  terrence.gunderson@sakilacustomer.org         601        True   \n",
      "595    enrique.forsythe@sakilacustomer.org         602        True   \n",
      "596      freddie.duggan@sakilacustomer.org         603        True   \n",
      "597       wade.delvalle@sakilacustomer.org         604        True   \n",
      "598      austin.cintron@sakilacustomer.org         605        True   \n",
      "\n",
      "    create_date             last_update  active  \n",
      "0    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "1    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "2    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "3    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "4    2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "..          ...                     ...     ...  \n",
      "594  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "595  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "596  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "597  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "598  2006-02-14 2013-05-26 14:49:45.738       1  \n",
      "\n",
      "[599 rows x 10 columns]\n",
      "\n",
      "Retrieved Data for payment:\n",
      "       payment_id  customer_id  staff_id  rental_id amount  \\\n",
      "0           17503          341         2       1520   7.99   \n",
      "1           17504          341         1       1778   1.99   \n",
      "2           17505          341         1       1849   7.99   \n",
      "3           17506          341         2       2829   2.99   \n",
      "4           17507          341         2       3130   7.99   \n",
      "...           ...          ...       ...        ...    ...   \n",
      "14591       32094          245         2      12682   2.99   \n",
      "14592       32095          251         1      14107   0.99   \n",
      "14593       32096          252         2      13756   4.99   \n",
      "14594       32097          263         1      15293   0.99   \n",
      "14595       32098          264         2      14243   2.99   \n",
      "\n",
      "                    payment_date  \n",
      "0     2007-02-15 22:25:46.996577  \n",
      "1     2007-02-16 17:23:14.996577  \n",
      "2     2007-02-16 22:41:45.996577  \n",
      "3     2007-02-19 19:39:56.996577  \n",
      "4     2007-02-20 17:31:48.996577  \n",
      "...                          ...  \n",
      "14591 2007-05-14 13:44:29.996577  \n",
      "14592 2007-05-14 13:44:29.996577  \n",
      "14593 2007-05-14 13:44:29.996577  \n",
      "14594 2007-05-14 13:44:29.996577  \n",
      "14595 2007-05-14 13:44:29.996577  \n",
      "\n",
      "[14596 rows x 6 columns]\n",
      "\n",
      "Retrieved Data for address:\n",
      "     address_id                   address address2      district  city_id  \\\n",
      "0             1         47 MySakila Drive     None       Alberta      300   \n",
      "1             2        28 MySQL Boulevard     None           QLD      576   \n",
      "2             3         23 Workhaven Lane     None       Alberta      300   \n",
      "3             4      1411 Lillydale Drive     None           QLD      576   \n",
      "4             5            1913 Hanoi Way               Nagasaki      463   \n",
      "..          ...                       ...      ...           ...      ...   \n",
      "598         601       844 Bucuresti Place               Liaoning      242   \n",
      "599         602  1101 Bucuresti Boulevard            West Greece      401   \n",
      "600         603    1103 Quilmes Boulevard                  Piura      503   \n",
      "601         604       1331 Usak Boulevard                   Vaud      296   \n",
      "602         605      1325 Fukuyama Street           Heilongjiang      537   \n",
      "\n",
      "    postal_code         phone         last_update  \n",
      "0                             2006-02-15 09:45:30  \n",
      "1                             2006-02-15 09:45:30  \n",
      "2                 14033335568 2006-02-15 09:45:30  \n",
      "3                  6172235589 2006-02-15 09:45:30  \n",
      "4         35200   28303384290 2006-02-15 09:45:30  \n",
      "..          ...           ...                 ...  \n",
      "598       36603  935952366111 2006-02-15 09:45:30  \n",
      "599       97661  199514580428 2006-02-15 09:45:30  \n",
      "600       52137  644021380889 2006-02-15 09:45:30  \n",
      "601       61960  145308717464 2006-02-15 09:45:30  \n",
      "602       27107  288241215394 2006-02-15 09:45:30  \n",
      "\n",
      "[603 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Data for rental:\n",
      "       rental_id         rental_date  inventory_id  customer_id  \\\n",
      "0              2 2005-05-24 22:54:33          1525          459   \n",
      "1              3 2005-05-24 23:03:39          1711          408   \n",
      "2              4 2005-05-24 23:04:41          2452          333   \n",
      "3              5 2005-05-24 23:05:21          2079          222   \n",
      "4              6 2005-05-24 23:08:07          2792          549   \n",
      "...          ...                 ...           ...          ...   \n",
      "16039      16046 2005-08-23 22:26:47          4364           74   \n",
      "16040      16047 2005-08-23 22:42:48          2088          114   \n",
      "16041      16048 2005-08-23 22:43:07          2019          103   \n",
      "16042      16049 2005-08-23 22:50:12          2666          393   \n",
      "16043          1 2005-05-24 22:53:30           367          130   \n",
      "\n",
      "              return_date  staff_id         last_update  \n",
      "0     2005-05-28 19:40:33         1 2006-02-16 02:30:53  \n",
      "1     2005-06-01 22:12:39         1 2006-02-16 02:30:53  \n",
      "2     2005-06-03 01:43:41         2 2006-02-16 02:30:53  \n",
      "3     2005-06-02 04:33:21         1 2006-02-16 02:30:53  \n",
      "4     2005-05-27 01:32:07         1 2006-02-16 02:30:53  \n",
      "...                   ...       ...                 ...  \n",
      "16039 2005-08-27 18:02:47         2 2006-02-16 02:30:53  \n",
      "16040 2005-08-25 02:48:48         2 2006-02-16 02:30:53  \n",
      "16041 2005-08-31 21:33:07         1 2006-02-16 02:30:53  \n",
      "16042 2005-08-30 01:01:12         2 2006-02-16 02:30:53  \n",
      "16043 2005-05-26 22:04:30         1 2006-02-15 21:30:53  \n",
      "\n",
      "[16044 rows x 7 columns]\n",
      "\n",
      "Retrieved Data for inventory:\n",
      "      inventory_id  film_id  store_id         last_update\n",
      "0                1        1         1 2006-02-15 10:09:17\n",
      "1                2        1         1 2006-02-15 10:09:17\n",
      "2                3        1         1 2006-02-15 10:09:17\n",
      "3                4        1         1 2006-02-15 10:09:17\n",
      "4                5        1         2 2006-02-15 10:09:17\n",
      "...            ...      ...       ...                 ...\n",
      "4576          4577     1000         1 2006-02-15 10:09:17\n",
      "4577          4578     1000         2 2006-02-15 10:09:17\n",
      "4578          4579     1000         2 2006-02-15 10:09:17\n",
      "4579          4580     1000         2 2006-02-15 10:09:17\n",
      "4580          4581     1000         2 2006-02-15 10:09:17\n",
      "\n",
      "[4581 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Displaying the items present in the database \n",
    "\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "# Function to query data from PostgreSQL\n",
    "def query_data(table_name):\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(f\"SELECT * FROM {table_name}\"))\n",
    "        data = result.fetchall()\n",
    "        return pd.DataFrame(data, columns=result.keys())\n",
    "\n",
    "# List of tables to query\n",
    "tables = ['actor', 'film', 'film_actor', 'customer', 'payment', 'address', 'rental', 'inventory']\n",
    "\n",
    "# Retrieve data from PostgreSQL and display all columns for each table\n",
    "for table in tables:\n",
    "    data = query_data(table)\n",
    "    print(f\"\\nRetrieved Data for {table}:\")\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eb87395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "675ba125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below code is to just print the name (Its a sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b84d6c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Data:\n",
      "   first_name     last_name\n",
      "0        Adam        Hopper\n",
      "1        Adam         Grant\n",
      "2          Al       Garland\n",
      "3        Alan      Dreyfuss\n",
      "4      Albert     Johansson\n",
      "..        ...           ...\n",
      "95     Johnny  Lollobrigida\n",
      "96     Johnny          Cage\n",
      "97        Jon         Chase\n",
      "98       Jude        Cruise\n",
      "99       Judy          Dean\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "User Input:\n",
      "First Name: John\n",
      "Last Name: Doe\n",
      "Error: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "# Function to query data from PostgreSQL\n",
    "def query_data():\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT first_name, last_name FROM actor ORDER BY first_name LIMIT 100\"))\n",
    "        data = result.fetchall()\n",
    "        return pd.DataFrame(data, columns=[\"first_name\", \"last_name\"])\n",
    "\n",
    "# Function to make predictions using a simple ML model\n",
    "def make_predictions(data):\n",
    "    # Example: Encode names as integers and predict if the name length is even or odd\n",
    "    le = LabelEncoder()\n",
    "    data['first_name_encoded'] = le.fit_transform(data['first_name'])\n",
    "    data['last_name_encoded'] = le.fit_transform(data['last_name'])\n",
    "\n",
    "    # Create and train a simple model (Logistic Regression for demonstration)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(data[['first_name_encoded', 'last_name_encoded']], data['first_name_encoded'])  # Not predicting odd or even, just demonstrating\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(data[['first_name_encoded', 'last_name_encoded']])\n",
    "    data['predictions'] = predictions\n",
    "    return data\n",
    "\n",
    "# Retrieve data from PostgreSQL\n",
    "data = query_data()\n",
    "print(\"Retrieved Data:\")\n",
    "print(data)\n",
    "\n",
    "# Hardcoded input\n",
    "first_name = \"John\"\n",
    "last_name = \"Doe\"\n",
    "\n",
    "# Display hardcoded input\n",
    "print(\"\\nUser Input:\")\n",
    "print(f\"First Name: {first_name}\")\n",
    "print(f\"Last Name: {last_name}\")\n",
    "\n",
    "# Make predictions using a local ML model\n",
    "try:\n",
    "    predicted_data = make_predictions(pd.DataFrame({\"first_name\": [first_name], \"last_name\": [last_name]}))\n",
    "    print(\"\\nPredictions:\")\n",
    "    print(predicted_data[['first_name', 'last_name', 'predictions']])\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87e93bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "020ff2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below code retrieves the first 10 rows of actors' first and last names from the actor table \n",
    "# and uses a simple logistic regression model to predict whether the combined length of the first \n",
    "# and last names is even or odd. (Returns true if even and false if odd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37252520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Data:\n",
      "   first_name    last_name\n",
      "0        Adam        Grant\n",
      "1        Adam       Hopper\n",
      "2          Al      Garland\n",
      "3        Alan     Dreyfuss\n",
      "4      Albert    Johansson\n",
      "5      Albert        Nolte\n",
      "6        Alec        Wayne\n",
      "7      Angela       Hudson\n",
      "8      Angela  Witherspoon\n",
      "9    Angelina      Astaire\n",
      "10       Anne       Cronyn\n",
      "11     Audrey      Olivier\n",
      "12     Audrey       Bailey\n",
      "13       Bela       Walken\n",
      "14        Ben       Willis\n",
      "\n",
      "Predictions:\n",
      "   first_name    last_name  predictions\n",
      "0        Adam        Grant        False\n",
      "1        Adam       Hopper        False\n",
      "2          Al      Garland        False\n",
      "3        Alan     Dreyfuss         True\n",
      "4      Albert    Johansson        False\n",
      "5      Albert        Nolte        False\n",
      "6        Alec        Wayne        False\n",
      "7      Angela       Hudson        False\n",
      "8      Angela  Witherspoon        False\n",
      "9    Angelina      Astaire         True\n",
      "10       Anne       Cronyn         True\n",
      "11     Audrey      Olivier        False\n",
      "12     Audrey       Bailey         True\n",
      "13       Bela       Walken        False\n",
      "14        Ben       Willis        False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "# Function to query data from PostgreSQL\n",
    "def query_data():\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT first_name, last_name FROM actor ORDER BY first_name LIMIT 15\"))\n",
    "        data = result.fetchall()\n",
    "        return pd.DataFrame(data, columns=[\"first_name\", \"last_name\"])\n",
    "\n",
    "# Function to make predictions using a simple ML model\n",
    "def make_predictions(data):\n",
    "    # Example: Encode names as integers and predict if the name length is even or odd\n",
    "    le = LabelEncoder()\n",
    "    data['first_name_encoded'] = le.fit_transform(data['first_name'])\n",
    "    data['last_name_encoded'] = le.fit_transform(data['last_name'])\n",
    "    data['name_length'] = data['first_name'].str.len() + data['last_name'].str.len()\n",
    "    data['is_even_length'] = data['name_length'] % 2 == 0\n",
    "\n",
    "    # Create and train a simple model (Logistic Regression for demonstration)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(data[['first_name_encoded', 'last_name_encoded']], data['is_even_length'])\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(data[['first_name_encoded', 'last_name_encoded']])\n",
    "    data['predictions'] = predictions\n",
    "    return data\n",
    "\n",
    "# Retrieve data from PostgreSQL\n",
    "data = query_data()\n",
    "print(\"Retrieved Data:\")\n",
    "print(data)\n",
    "\n",
    "# Make predictions using a local ML model\n",
    "predicted_data = make_predictions(data)\n",
    "print(\"\\nPredictions:\")\n",
    "print(predicted_data[['first_name', 'last_name', 'predictions']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "842ac4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66eb8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to the above one but to Retrieve the first 15 film titles and Calculate the title length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3de21a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (2.0.30)\n",
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2_binary-2.9.9-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\adity\\appdata\\roaming\\python\\python39\\site-packages (from sqlalchemy) (4.12.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\adity\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\psycopg2\\\\_psycopg.cp39-win_amd64.pyd'\n",
      "Check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: psycopg2-binary\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy psycopg2-binary scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbbff54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Data:\n",
      "                 title\n",
      "0     Academy Dinosaur\n",
      "1       Ace Goldfinger\n",
      "2     Adaptation Holes\n",
      "3     Affair Prejudice\n",
      "4          African Egg\n",
      "..                 ...\n",
      "995     Young Language\n",
      "996         Youth Kick\n",
      "997       Zhivago Core\n",
      "998  Zoolander Fiction\n",
      "999          Zorro Ark\n",
      "\n",
      "[1000 rows x 1 columns]\n",
      "Enter a film title: Zorro Ark\n",
      "\n",
      "User Input:\n",
      "Zorro Ark\n",
      "\n",
      "Predictions:\n",
      "                 title  predictions\n",
      "0     Academy Dinosaur         True\n",
      "1       Ace Goldfinger         True\n",
      "2     Adaptation Holes         True\n",
      "3     Affair Prejudice         True\n",
      "4          African Egg         True\n",
      "..                 ...          ...\n",
      "995     Young Language         True\n",
      "996         Youth Kick         True\n",
      "997       Zhivago Core         True\n",
      "998  Zoolander Fiction         True\n",
      "999          Zorro Ark         True\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "db_user = 'postgres'\n",
    "db_password = '187781'\n",
    "db_host = 'localhost'\n",
    "db_port = '5432'\n",
    "db_name = 'dvdrental'\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"postgresql://postgres:187781@localhost:5432/dvdrental\")\n",
    "\n",
    "def query_data():\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(\"SELECT title FROM film ORDER BY title\"))\n",
    "        data = result.fetchall()\n",
    "        return pd.DataFrame(data, columns=[\"title\"])\n",
    "\n",
    "# Function to make predictions using a simple ML model\n",
    "def make_predictions(data):\n",
    "    # Example: Encode titles as integers and predict if the title length is greater than 10\n",
    "    le = LabelEncoder()\n",
    "    data['title_encoded'] = le.fit_transform(data['title'])\n",
    "    data['title_length'] = data['title'].str.len()\n",
    "    data['is_long_title'] = data['title_length'] > 10\n",
    "\n",
    "    # Ensure we have both classes in the dataset\n",
    "    if data['is_long_title'].nunique() == 1:\n",
    "        raise ValueError(\"The dataset contains only one class after encoding. Please ensure your dataset contains both classes.\")\n",
    "\n",
    "    # Create and train a simple model (Logistic Regression for demonstration)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(data[['title_encoded']], data['is_long_title'])\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(data[['title_encoded']])\n",
    "    data['predictions'] = predictions\n",
    "    return data\n",
    "\n",
    "# Retrieve data from PostgreSQL\n",
    "data = query_data()\n",
    "print(\"Retrieved Data:\")\n",
    "print(data)\n",
    "\n",
    "# Take user input\n",
    "user_input = input(\"Enter a film title: \")\n",
    "\n",
    "# Display user input\n",
    "print(\"\\nUser Input:\")\n",
    "print(user_input)\n",
    "\n",
    "# Make predictions using a local ML model\n",
    "try:\n",
    "    predicted_data = make_predictions(data)\n",
    "    print(\"\\nPredictions:\")\n",
    "    print(predicted_data[['title', 'predictions']])\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1a09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
